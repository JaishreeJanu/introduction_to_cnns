{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise - 2 Data Augmentation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:27:23.251092Z",
     "start_time": "2021-06-27T19:27:21.267223Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import CIFAR10\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show\n",
    "from bokeh.models import LinearAxis, Range1d\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:27:55.669845Z",
     "start_time": "2021-06-27T19:27:55.661638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 6\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "DATA_PATH = '/home/jaishree/Documents/DA Sem 1/DDA Lab/CNN_image_classification/cifar-10'\n",
    "MODEL_PATH = '/home/jaishree/Documents/DA Sem 1/DDA Lab/CNN_image_classification/results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:29:15.619947Z",
     "start_time": "2021-06-27T19:29:15.613579Z"
    }
   },
   "outputs": [],
   "source": [
    "## Data Augmentation and normalization\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Scale((64,64)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Scale((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T08:36:52.793158Z",
     "start_time": "2021-06-26T08:36:52.782746Z"
    }
   },
   "outputs": [],
   "source": [
    "## Normalization\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:29:23.164747Z",
     "start_time": "2021-06-27T19:29:18.438416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CIFAR10(root = DATA_PATH, download=True, transform=transform_train)\n",
    "test_dataset = CIFAR10(root = DATA_PATH, train=False, transform=transform_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:30:17.108846Z",
     "start_time": "2021-06-27T19:30:17.054400Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data Augmentation: the process of artificially ’increasing’ our dataset by adding translation, scaling \n",
    "#and flipping to the images to fabricate examples for training.\n",
    "\n",
    "train_len = 25*1000\n",
    "part_train = torch.utils.data.random_split(train_dataset, [train_len, len(train_dataset)-train_len])[0]\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=part_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T19:30:28.169333Z",
     "start_time": "2021-06-27T19:30:28.153869Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(15*15*128, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)       \n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T20:43:40.728213Z",
     "start_time": "2021-06-27T20:43:40.526373Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "\n",
    "# Loss and opitimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-06-27T20:43:44.690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Step [250/250], training Loss: 0.0396, training Accuracy: 14.00%\n",
      "Epoch [2/6], Step [250/250], training Loss: 0.0356, training Accuracy: 28.68%\n",
      "Epoch [3/6], Step [250/250], training Loss: 0.0340, training Accuracy: 35.82%\n",
      "Epoch [4/6], Step [250/250], training Loss: 0.0329, training Accuracy: 39.73%\n",
      "Epoch [5/6], Step [250/250], training Loss: 0.0310, training Accuracy: 43.20%\n",
      "Epoch [6/6], Step [250/250], training Loss: 0.0268, training Accuracy: 49.12%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "            \n",
    "        # Run the forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        train_acc.append(correct / total)\n",
    "\n",
    "    tb.add_scalar(\"Both Train Loss\", total_loss/len(part_train), epoch)\n",
    "    tb.add_scalar(\"Both Train Accuracy\", total_correct/len(part_train), epoch)\n",
    "        \n",
    "    print('Epoch [{}/{}], Step [{}/{}], training Loss: {:.4f}, training Accuracy: {:.2f}%'\n",
    "              .format(epoch + 1, num_epochs, i + 1, total_step, total_loss/len(part_train),\n",
    "                      (total_correct / len(part_train)) * 100))\n",
    "\n",
    "    \n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T20:30:39.050696Z",
     "start_time": "2021-06-27T20:30:11.673091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on all test images: 49.0 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "test_int_acc = []\n",
    "test_int_loss = []\n",
    "\n",
    "int_correct = 0\n",
    "int_total = 0\n",
    "int_total_loss = 0\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (int_images, int_labels) in enumerate(test_loader):\n",
    "        int_outputs = model(int_images)\n",
    "        int_loss = criterion(int_outputs, int_labels)\n",
    "        test_int_loss.append(int_loss.item())\n",
    "        int_total_loss += int_loss.item()\n",
    "\n",
    "        _, predicted = torch.max(int_outputs.data, 1)\n",
    "        int_total += int_labels.size(0)\n",
    "        int_correct += (predicted == int_labels).sum().item()\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        test_int_acc.append(correct / int_labels.size(0))\n",
    "        \n",
    "        tb.add_scalar(\" Both Test Loss\", int_loss.item(), i)\n",
    "        tb.add_scalar(\"Both Test Accuracy\", correct, i)\n",
    "\n",
    "    print('Test Accuracy of the model on all test images: {} %'.format((int_correct / int_total) * 100))\n",
    "    \n",
    "\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-27T20:34:45.771088Z",
     "start_time": "2021-06-27T20:34:45.634355Z"
    }
   },
   "outputs": [],
   "source": [
    "p = figure(y_axis_label='Loss', width=850, y_range=(0, 5), title='PyTorch ConvNet results')\n",
    "p.extra_y_ranges = {'Accuracy': Range1d(start=0, end=100)}\n",
    "p.add_layout(LinearAxis(y_range_name='Accuracy', axis_label='Accuracy (%)'), 'right')\n",
    "p.line(np.arange(len(train_loss)), train_loss, color='green')\n",
    "p.line(np.arange(len(train_loss)), np.array(train_acc) * 100, y_range_name='Accuracy', color='red')\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
